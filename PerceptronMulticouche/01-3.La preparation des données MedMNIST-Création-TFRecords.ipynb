{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5d4c0c6-8c2a-470d-8557-6ffcdfa08343",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>                                                                                   \n",
    "     <th>\n",
    "         <div style='padding:15px;color:#030aa7;font-size:240%;text-align: center;font-style: italic;font-weight: bold;font-family: Georgia, serif'><a href=\"https://www.kaggle.com/datasets/arashnic/standardized-biomedical-images-medmnist\">MedMNIST<br> Standardized Biomedical Images</a></div>\n",
    "     </th>\n",
    "     <th><img src=\"https://raw.githubusercontent.com/rbizoi/DeepLearning/refs/heads/main/images/medminstico.jpg\" width=\"96\"></th>\n",
    " </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr> \n",
    "        <th>\n",
    "        <div style='text-align: center'>\n",
    "        <img src=\"https://raw.githubusercontent.com/rbizoi/DeepLearning/refs/heads/main/images/medmnistv2.jpg\" width=\"512\">\n",
    "        </div>\n",
    "        </th>\n",
    "        <th>\n",
    "        <div style='text-align: center'>\n",
    "        <img src=\"https://raw.githubusercontent.com/rbizoi/DeepLearning/refs/heads/main/images/medminstico.png\" width=\"512\">\n",
    "        </div>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<div style='text-align: center'>\n",
    "        <img src=\"https://raw.githubusercontent.com/rbizoi/DeepLearning/refs/heads/main/images/medminstdataset.png\" width=\"1024\">\n",
    "</div>\n",
    "\n",
    "<div style='padding:15px;color:#030aa7;font-size:100%;text-align: left;font-family: Georgia, serif'><a href=\"https://github.com/MedMNIST/MedMNIST/tree/main\">Veuillez vous référer à la page Github officielle pour plus de détails.</a></div>\n",
    "\n",
    ">> **site du projet** : https://medmnist.com/\n",
    "\n",
    ">> **site de données**>> **site de données** : https://zenodo.org/records/10519652 : https://zenodo.org/records/10519652\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8b7e6c-37b3-4448-ad37-19fdd4e28c2b",
   "metadata": {},
   "source": [
    "# <b><div style='padding:18px;background-color:#d8dcd6;color:#030aa7;font-size:130%; border-radius:12px 12px; box-shadow: 8px 8px 8px #042b4c;text-align: left'>Introduction</div></b>"
   ]
  },
  {
   "cell_type": "code",
   "id": "a05a05ee-1020-4e86-9fd4-5fc88477865e",
   "metadata": {},
   "source": [
    "import os\n",
    "# import json\n",
    "# @param [\"tensorflow\", \"jax\", \"torch\"]\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'  \n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "# os.environ['TF_XLA_FLAGS']='--tf_xla_auto_jit=1,--tf_xla_always_defer_compilation=true'\n",
    "# os.environ['XLA_FLAGS']='--xla_backend_optimization_level=0,--xla_gpu_autotune_level=4,--xla_gpu_disable_ptxas_optimizations=true,--xla_gpu_use_cudnn_batchnorm_level=2'\n",
    "# os.environ['TF_GPU_ALLOCATOR']='cuda_malloc_async'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='5'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bcd822dd-1a90-4bd8-b0db-9e4c19be1761",
   "metadata": {},
   "source": [
    "! nvidia-smi"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5727e3ae-20fe-40e5-8324-dab5e13ee23a",
   "metadata": {},
   "source": [
    "## <b><div style='padding:15px;background-color:#d8dcd6;color:#030aa7;font-size:100%; border-radius:10px 10px; box-shadow: 8px 8px 8px #042b4c;text-align: left'>Import libriries </div></b>"
   ]
  },
  {
   "cell_type": "code",
   "id": "8046e7ef-57a7-4087-b35e-804b7c74a783",
   "metadata": {},
   "source": [
    "import numpy as np, pandas as pd, seaborn as sns, warnings, sys, pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "if int(str(sns.__version__).split('.')[1]) > 8 : \n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "else:\n",
    "    plt.style.use('seaborn-darkgrid')\n",
    "    \n",
    "sns.set(font_scale=2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ba2616c4-3814-4ea6-adc9-7ff10460bd7a",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')# Suppress TensorFlow logging (2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0d73afa6-4356-4652-af6a-a80e269a3421",
   "metadata": {},
   "source": [
    "print(\"Tensorflow\\t : %s\\tCUDA %s\\tGPU %s\\tXLA %s\\nKeras\\t\\t : %s\\nPandas\\t\\t : %s\\nNumPy\\t\\t : %s\"%\n",
    "      (tf.__version__, \n",
    "       tf.test.is_built_with_cuda(), \n",
    "       tf.test.is_built_with_gpu_support(), \n",
    "       tf.test.is_built_with_xla(), \n",
    "       tf.keras.__version__, \n",
    "       pd.__version__, \n",
    "       np.__version__))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4c7b3683-140f-46f0-a5d2-970a7629b42c",
   "metadata": {},
   "source": [
    "## <b><div style='padding:15px;background-color:#d8dcd6;color:#030aa7;font-size:100%; border-radius:10px 10px; box-shadow: 8px 8px 8px #042b4c;text-align: left'>Initialisation les GPUs presents </div></b>"
   ]
  },
  {
   "cell_type": "code",
   "id": "228446fe-f632-453c-af90-df49f751f880",
   "metadata": {},
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if len(physical_devices) >  0 :\n",
    "    for i, gpu in enumerate(physical_devices):\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[i], True)\n",
    "\n",
    "    strategy = tf.distribute.experimental.CentralStorageStrategy()\n",
    "    print('Le système est initialisé avec {0:d} GPUs'.format(strategy.num_replicas_in_sync))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3c1dc190-93a5-4bca-b1ff-d4d724b26b91",
   "metadata": {},
   "source": [
    "## <b><div style='padding:15px;background-color:#d8dcd6;color:#030aa7;font-size:100%; border-radius:10px 10px; box-shadow: 8px 8px 8px #042b4c;text-align: left'>Outils du document </div></b>"
   ]
  },
  {
   "cell_type": "code",
   "id": "26190396-a3c7-4561-a795-dc0f398a7dcf",
   "metadata": {},
   "source": [
    "palette = [\n",
    "            \"#030aa7\", \"#e50000\", \"#d8863b\", \"#005f6a\", \"#6b7c85\", \"#751973\", \"#d1e5f0\", \"#fddbc7\",\n",
    "            \"#ffffcb\", \"#12e193\", \"#d8dcd6\", \"#ffdaf0\", \"#dfc5fe\", \"#f5054f\", \"#a0450e\",\n",
    "            \"#0339f8\", \"#f4320c\", \"#fec615\", \"#017a79\", \"#85a3b2\", \"#fe2f4a\", \"#a00498\", \"#b04e0f\",\n",
    "            \"#0165fc\", \"#ff724c\", \"#fddc5c\", \"#11875d\", \"#89a0b0\", \"#fe828c\", \"#cb00f5\", \"#b75203\",\n",
    "            \"#0485d1\", \"#ff7855\", \"#fbeeac\", \"#0cb577\", \"#95a3a6\", \"#ffb7ce\", \"#c071fe\", \"#ca6b02\",\n",
    "            \"#92c5de\", \"#f4a582\", \"#fef69e\", \"#18d17b\", \"#c5c9c7\", \"#ffcfdc\", \"#caa0ff\", \"#cb7723\",\n",
    "            \"#d1e5f0\", \"#fddbc7\", \"#ffffcb\", \"#12e193\", \"#d8dcd6\", \"#ffdaf0\", \"#dfc5fe\", \"#d8863b\",\n",
    "            \"#030764\", \"#be0119\", \"#dbb40c\", \"#005249\", \"#3c4142\", \"#cb0162\", \"#5d1451\", \"#653700\",\n",
    "            \"#040348\", \"#67001f\", \"#b27a01\", \"#002d04\", \"#000000\", \"#a0025c\", \"#490648\", \"#3c0008\"\n",
    "          ]\n",
    "# sns.palplot(sns.color_palette(palette))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d49cc2ad-938a-42ec-aba7-10c2df57fa32",
   "metadata": {},
   "source": [
    "nom_projet                = \"MedMNIST-donnees\"\n",
    "repertoireProjet          = os.getcwd()\n",
    "repertoireEnregistrement  = repertoireProjet +'/'+nom_projet+ '/repertoire.images'\n",
    "repertoireSauvegardes     = repertoireProjet +'/'+nom_projet+ '/repertoire.sauvegardes'\n",
    "\n",
    "def controleExistenceRepertoire(directory, create_if_needed=True):\n",
    "    \"\"\"Voir si le répertoire existe. S'il n'existe pas il est créé.\"\"\"\n",
    "    path_exists = os.path.exists(directory)\n",
    "    if path_exists:\n",
    "        if not os.path.isdir(directory):\n",
    "            raise Exception(\"Trouvé le nom \"+directory+\" mais c'est un fichier, pas un répertoire\")\n",
    "            return False\n",
    "        return True\n",
    "    if create_if_needed:\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "controleExistenceRepertoire(repertoireEnregistrement)\n",
    "controleExistenceRepertoire(repertoireSauvegardes)\n",
    "\n",
    "def sauvegarderImage( fichier):\n",
    "    \"\"\"Enregistrez la figure. Appelez la méthode juste avant plt.show ().\"\"\"\n",
    "    plt.savefig(os.path.join(repertoireEnregistrement,\n",
    "                             fichier+f\"--{dt.now().strftime('%Y_%m_%d_%H.%M.%S')}.png\"), \n",
    "                             dpi=600, \n",
    "                             bbox_inches='tight')\n",
    "\n",
    "\n",
    "    \n",
    "def sauvegarderModelPoids(model, fichierPoids, repertoireSauvegardes=repertoireSauvegardes):\n",
    "    \"\"\"Enregistrez les poids du modèle Keras.\"\"\"\n",
    "    if fichierPoids != None:\n",
    "        controleExistenceRepertoire(repertoireSauvegardes)\n",
    "        nomFichier = os.path.join(repertoireSauvegardes, '{}.keras'.format(fichierPoids))\n",
    "        model.save_weights(nomFichier)\n",
    "\n",
    "def sauvegarderModel(model, fichier, repertoireSauvegardes=repertoireSauvegardes):\n",
    "    \"\"\"Enregistrez le modèle Keras.\"\"\"\n",
    "    if fichier != None:\n",
    "        controleExistenceRepertoire(repertoireSauvegardes)\n",
    "        nomFichier = os.path.join(repertoireSauvegardes, '{}.keras'.format(fichier))\n",
    "        model.save(nomFichier)\n",
    "\n",
    "def lectureModelPoids(model, fichier, repertoireSauvegardes=repertoireSauvegardes):\n",
    "    \"\"\"Si le fichier existe, il est chargé et retourne True, sinon retourne False.\"\"\"\n",
    "    nomFichier = os.path.join(repertoireSauvegardes, '{}.keras'.format(fichier))\n",
    "    if os.path.exists(nomFichier):\n",
    "        if os.path.isfile(nomFichier):\n",
    "            model.load_weights(nomFichier)\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def lectureModel(self, model_filename):\n",
    "    \"\"\"Si le fichier existe, il est chargé et retourne True, sinon retourne False.\"\"\"\n",
    "    fullpath = self.saved_models_dir+'/'+model_filename+'.keras'\n",
    "    if os.path.exists(fullpath):\n",
    "        if os.path.isfile(fullpath):\n",
    "            model = load_model(fullpath)\n",
    "            return model\n",
    "    return None    \n",
    "\n",
    "def sauvegardeHistorique(model,\n",
    "                         repertoireSauvegardes,\n",
    "                         nomSauvegarde='one_hidden_layer_history_batch_size_1'):\n",
    "\n",
    "    history = pd.DataFrame( model.history)\n",
    "    history.reset_index(inplace=True)\n",
    "    history.rename(columns={'index':'epoch'},inplace=True)\n",
    "    history.to_parquet(os.path.join(repertoireSauvegardes,f'{nomSauvegarde}.gzip'),compression='gzip', engine='pyarrow') \n",
    "    return history\n",
    "\n",
    "def afficheHistoriqueEntrainement(history, palette):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2,figsize=(48,16));\n",
    "    markersize = 8\n",
    "    linewidth=2\n",
    "    \n",
    "    graph = sns.lineplot(x='epoch', \n",
    "                         y='accuracy',  \n",
    "                         data=history,\n",
    "                         ax=ax[0],      \n",
    "                         label='accuracy',\n",
    "                         err_style=None, \n",
    "                         marker='o',\n",
    "                         markersize=markersize,\n",
    "                         linewidth=linewidth,\n",
    "                         color=palette[0],\n",
    "                         );\n",
    "    graph = sns.lineplot(x='epoch', \n",
    "                         y='val_accuracy',  \n",
    "                         data=history,\n",
    "                         ax=ax[0],      \n",
    "                         label='val_accuracy',\n",
    "                         err_style=None, \n",
    "                         marker='o',\n",
    "                         markersize=markersize,\n",
    "                         linewidth=linewidth,\n",
    "                         color=palette[1],\n",
    "                         );\n",
    "    \n",
    "    graph = sns.lineplot(x='epoch', \n",
    "                         y='loss',  \n",
    "                         data=history,\n",
    "                         ax=ax[1],      \n",
    "                         label='loss',\n",
    "                         err_style=None, \n",
    "                         marker='o',\n",
    "                         markersize=markersize,\n",
    "                         linewidth=linewidth,\n",
    "                         color=palette[0],\n",
    "                         );\n",
    "    graph = sns.lineplot(x='epoch', \n",
    "                         y='val_loss',  \n",
    "                         data=history,\n",
    "                         ax=ax[1],      \n",
    "                         label='val_loss',\n",
    "                         err_style=None, \n",
    "                         marker='o',\n",
    "                         markersize=markersize,\n",
    "                         linewidth=linewidth,\n",
    "                         color=palette[1],\n",
    "                         );\n",
    "    sauvegarderImage('afficheHistoriqueEntrainement')\n",
    "    "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "33fa6a50-ac6f-48cd-b6ad-39fda10a2af7",
   "metadata": {},
   "source": [
    "# <b><div style='padding:18px;background-color:#d8dcd6;color:#030aa7;font-size:130%; border-radius:12px 12px; box-shadow: 8px 8px 8px #042b4c;text-align: left'>Lecture des données à partir du disque</div></b>"
   ]
  },
  {
   "cell_type": "code",
   "id": "beb9d408-4d23-44e5-87f2-f0b82514a7ec",
   "metadata": {},
   "source": [
    "def afficheDataset(donnees,labels,taille,image,dictLabels,cmap=None):\n",
    "    plt.figure(figsize=(image, image))\n",
    "    i=1\n",
    "    for image, label in zip(donnees[:(taille*taille)],labels[:(taille*taille)]):\n",
    "        ax = plt.subplot(taille, taille, i)\n",
    "        if cmap is None :\n",
    "            plt.imshow(image)\n",
    "        else :\n",
    "            plt.imshow(image,cmap='gray')\n",
    "        plt.title(dictLabels[label[0]])\n",
    "        plt.axis(\"off\")\n",
    "        i+=1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "eafdedd3-56d3-4401-9a92-55b4c099897c",
   "metadata": {},
   "source": [
    "## <b><div style='padding:15px;background-color:#d8dcd6;color:#030aa7;font-size:100%; border-radius:10px 10px; box-shadow: 8px 8px 8px #042b4c;text-align: left'>PathMNIST - RGB</div></b>\n",
    "\n",
    "The **PathMNIST** is based on a prior study for predicting survival from colorectal cancer histology slides, providing a dataset (**NCT-CRC-HE-100K**) of **100,000** non-overlapping image patches from hematoxylin & eosin stained histological images, and a test dataset (**CRC-VAL-HE-7K**) of **7,180** image patches from a different clinical center.<br>\n",
    "The dataset is comprised of **9** types of tissues, resulting in a multi-class classification task. <br>\n",
    "We resize the source images of 3×224×224 into 3×28×28, and split **NCT-CRC-HE-100K** into training and validation set with a ratio of 9:1.<br> The **CRC-VAL-HE-7K** is treated as the test set.\n",
    "\n",
    ">> https://zenodo.org/records/10519652/files/pathmnist.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/pathmnist_64.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/pathmnist_128.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/pathmnist_224.npz\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "7c4f106c-8184-4793-8c6d-0cd6354a7323",
   "metadata": {},
   "source": [
    "donnees = np.load(\"../donnees/MedMNIST(Standardized Biomedical Image)/pathmnist_64.npz\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9bbab62e-41e7-4e27-ac34-ac29d0d15f66",
   "metadata": {},
   "source": [
    "print(f'apprentissage\\t{donnees[\"train_images\"].shape[0]}\\nvalidation\\t{donnees[\"val_images\"].shape[0]}\\ntest\\t\\t{donnees[\"test_images\"].shape[0]}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ab9eceed-a50a-4230-aacd-a03491f345c6",
   "metadata": {},
   "source": [
    "dictLabels = {0:\"adipose\",\n",
    "              1:\"background\",\n",
    "              2:\"debris\",\n",
    "              3:\"lymphocytes\",\n",
    "              4:\"mucus\",\n",
    "              5:\"smooth\\nmuscle\",\n",
    "              6:\"normal\\ncolon mucosa\",\n",
    "              7:\"cancer-associated\\nstroma\",\n",
    "              8:\"colorectal\\nadenocarcinoma\\nepithelium\"}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "57e063ed-c4a7-4ea1-8dcd-881be7686ed0",
   "metadata": {},
   "source": [
    "afficheDataset(donnees[\"train_images\"],donnees[\"train_labels\"],taille=10,image=64,dictLabels=dictLabels)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b945e422-7a98-44fe-ae67-fb82de840028",
   "metadata": {},
   "source": [
    "## <b><div style='padding:15px;background-color:#d8dcd6;color:#030aa7;font-size:100%; border-radius:10px 10px; box-shadow: 8px 8px 8px #042b4c;text-align: left'>ChestMNIST - Grey</div></b>\n",
    "\n",
    "The **ChestMNIST** is based on the **NIH-ChestXray14** dataset, a dataset comprising **112,120** frontal-view X-Ray images of **30,805** unique patients with the text-mined **14** disease labels, which could be formulized as a multi-label binary-class classification task.<br>\n",
    "We use the official data split, and resize the source images of 1×1024×1024 into 1×28×28.\n",
    "\n",
    ">> https://zenodo.org/records/10519652/files/chestmnist.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/chestmnist_64.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/chestmnist_128.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/chestmnist_224.npz<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "a64494ba-b483-442b-bbd5-b1f72e941141",
   "metadata": {},
   "source": [
    "donnees = np.load(\"../donnees/MedMNIST(Standardized Biomedical Image)/chestmnist.npz\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1e330583-b3cf-4f8c-9873-5d2a26cc2dda",
   "metadata": {},
   "source": [
    "print(f'apprentissage\\t{donnees[\"train_images\"].shape[0]}\\nvalidation\\t{donnees[\"val_images\"].shape[0]}\\ntest\\t\\t{donnees[\"test_images\"].shape[0]}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "da068857-fb76-46c2-ad61-56c203e46948",
   "metadata": {},
   "source": [
    "dictLabels = {\n",
    "0: \"atelectasis\",\n",
    "1: \"cardiomegaly\",\n",
    "2: \"effusion\",\n",
    "3: \"infiltration\",\n",
    "4: \"mass\",\n",
    "5: \"nodule\",\n",
    "6: \"pneumonia\",\n",
    "7: \"pneumothorax\",\n",
    "8: \"consolidation\",\n",
    "9: \"edema\",\n",
    "10: \"emphysema\",\n",
    "11: \"fibrosis\",\n",
    "12: \"pleural\",\n",
    "13: \"hernia\"\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bfa4da51-b472-4023-b1c4-6290b345a418",
   "metadata": {},
   "source": [
    "afficheDataset(donnees[\"train_images\"],donnees[\"train_labels\"],taille=10,image=64,dictLabels=dictLabels,cmap='gray')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1b9ec762-86b2-472b-8765-a54734e50d35",
   "metadata": {},
   "source": [
    "## <b><div style='padding:15px;background-color:#d8dcd6;color:#030aa7;font-size:100%; border-radius:10px 10px; box-shadow: 8px 8px 8px #042b4c;text-align: left'>DermaMNIST - RGB</div></b>\n",
    "\n",
    "The **DermaMNIST** is based on the **HAM10000**, a large collection of multi-source dermatoscopic images of common pigmented skin lesions.<br>\n",
    "The dataset consists of **10,015** dermatoscopic images categorized as 7 different diseases, formulized as a multi-class classification task. <br>\n",
    "We split the images into training, validation and test set with a ratio of 7:1:2. The source images of 3×600×450 are resized into 3×28×28.\n",
    "\n",
    ">> https://zenodo.org/records/10519652/files/dermamnist.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/dermamnist_64.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/dermamnist_128.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/dermamnist_224.npz<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "b4d4f74f-2732-4fc2-b868-865617127cfd",
   "metadata": {},
   "source": [
    "donnees = np.load(\"../donnees/MedMNIST(Standardized Biomedical Image)/dermamnist_64.npz\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3eb8ba33-d6ba-4b15-b3ef-aaefae4df4f5",
   "metadata": {},
   "source": [
    "print(f'apprentissage\\t{donnees[\"train_images\"].shape[0]}\\nvalidation\\t{donnees[\"val_images\"].shape[0]}\\ntest\\t\\t{donnees[\"test_images\"].shape[0]}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6013c47a-fcf9-47d4-bb86-8cdf38b21cda",
   "metadata": {},
   "source": [
    "dictLabels = {\n",
    "0:\"actinic keratoses and intraepithelial carcinoma\",\n",
    "1:\"basal cell carcinoma\",\n",
    "2:\"benign keratosis-like lesions\",\n",
    "3:\"dermatofibroma\",\n",
    "4:\"melanoma\",\n",
    "5:\"melanocytic nevi\",\n",
    "6:\"vascular lesions\"\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d8c331de-8d46-4bbe-b8ab-b329f77365fe",
   "metadata": {},
   "source": [
    "afficheDataset(donnees[\"train_images\"],donnees[\"train_labels\"],taille=10,image=64,dictLabels=dictLabels)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "519e9f05-3fd7-46bd-ae47-aaa5278483b2",
   "metadata": {},
   "source": [
    "## <b><div style='padding:15px;background-color:#d8dcd6;color:#030aa7;font-size:100%; border-radius:10px 10px; box-shadow: 8px 8px 8px #042b4c;text-align: left'>OCTMNIST - Grey</div></b>\n",
    "\n",
    "The **OCTMNIST** is based on a prior dataset of **109,309** valid optical coherence tomography (OCT) images for retinal diseases. The dataset is comprised of 4 diagnosis categories, leading to a multi-class classification task. We split the source training set with a ratio of 9:1 into training and validation set, and use its source validation set as the test set. The source images are gray-scale, and their sizes are (384−1,536)×(277−512). We center-crop the images and resize them into 1×28×28.\n",
    "\n",
    ">> https://zenodo.org/records/10519652/files/octmnist.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/octmnist_64.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/octmnist_128.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/octmnist_224.npz\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "92209442-b98d-4c71-82a0-91b88aa8e21f",
   "metadata": {},
   "source": [
    "donnees = np.load(\"../donnees/MedMNIST(Standardized Biomedical Image)/octmnist_64.npz\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bcc7934b-f4b3-497c-846b-813af2c03235",
   "metadata": {},
   "source": [
    "print(f'apprentissage\\t{donnees[\"train_images\"].shape[0]}\\nvalidation\\t{donnees[\"val_images\"].shape[0]}\\ntest\\t\\t{donnees[\"test_images\"].shape[0]}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2117a9cb-1ba8-409e-a4d2-076058bd51e9",
   "metadata": {},
   "source": [
    "dictLabels = {\n",
    "0: \"choroidal\\nneovascularization\",\n",
    "1: \"diabetic\\nmacular\\nedema\",\n",
    "2: \"drusen\",\n",
    "3: \"normal\"\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b05af59e-2eb0-4b69-a4d0-974a3241ed17",
   "metadata": {},
   "source": [
    "afficheDataset(donnees[\"train_images\"],donnees[\"train_labels\"],taille=10,image=64,dictLabels=dictLabels,cmap='gray')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8b4b9e5a-d515-4111-bd2b-cba638889ba2",
   "metadata": {},
   "source": [
    "## <b><div style='padding:15px;background-color:#d8dcd6;color:#030aa7;font-size:100%; border-radius:10px 10px; box-shadow: 8px 8px 8px #042b4c;text-align: left'>PneumoniaMNIST - Grey</div></b>\n",
    "\n",
    "The **PneumoniaMNIST** is based on a prior dataset of **5,856** pediatric chest X-Ray images. The task is binary-class classification of pneumonia against normal. We split the source training set with a ratio of 9:1 into training and validation set and use its source validation set as the test set. The source images are gray-scale, and their sizes are (384−2,916)×(127−2,713). We center-crop the images and resize them into 1×28×28.\n",
    "\n",
    ">> https://zenodo.org/records/10519652/files/pneumoniamnist.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/pneumoniamnist_64.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/pneumoniamnist_128.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/pneumoniamnist_224.npz\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "6ca7dcea-92bb-4ed4-b1de-d60efeff49c6",
   "metadata": {},
   "source": [
    "donnees = np.load(\"../donnees/MedMNIST(Standardized Biomedical Image)/pneumoniamnist.npz\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6e512830-9552-4283-aa8f-f6b489e511a3",
   "metadata": {},
   "source": [
    "print(f'apprentissage\\t{donnees[\"train_images\"].shape[0]}\\nvalidation\\t{donnees[\"val_images\"].shape[0]}\\ntest\\t\\t{donnees[\"test_images\"].shape[0]}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c4321bea-b365-426d-af41-ab9e418e38c4",
   "metadata": {},
   "source": [
    "dictLabels = {\n",
    "0: \"normal\",\n",
    "1: \"pneumonia\"\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b2c5bf2d-ff21-4f8b-9602-61520f3daa65",
   "metadata": {},
   "source": [
    "afficheDataset(donnees[\"train_images\"],donnees[\"train_labels\"],taille=20,image=64,dictLabels=dictLabels,cmap='gray')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0f5cecf6-270d-45ed-bb2b-866f15ff7a56",
   "metadata": {},
   "source": [
    "## <b><div style='padding:15px;background-color:#d8dcd6;color:#030aa7;font-size:100%; border-radius:10px 10px; box-shadow: 8px 8px 8px #042b4c;text-align: left'>RetinaMNIST - RGB</div></b>\n",
    "\n",
    "The **RetinaMNIST** is based on the **DeepDRiD** challenge, which provides a dataset of **1,600** retina fundus images.<br> \n",
    "The task is ordinal regression for 5-level grading of **diabetic retinopathy severity**.<br> \n",
    "We split the source training set with a ratio of 9:1 into training and validation set, and use the source validation set as the test set.<br>\n",
    "The source images of 3×1,736×1,824 are center-cropped and resized into 3×28×28.\n",
    "\n",
    ">> https://zenodo.org/records/10519652/files/retinamnist.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/retinamnist_64.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/retinamnist_128.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/retinamnist_224.npz\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "fda4b0b4-35c3-46eb-8f6b-8452f3cf4bc2",
   "metadata": {},
   "source": [
    "donnees = np.load(\"../donnees/MedMNIST(Standardized Biomedical Image)/retinamnist.npz\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f101853e-0b46-4df4-8549-1eb4f01fd571",
   "metadata": {},
   "source": [
    "print(f'apprentissage\\t{donnees[\"train_images\"].shape[0]}\\nvalidation\\t{donnees[\"val_images\"].shape[0]}\\ntest\\t\\t{donnees[\"test_images\"].shape[0]}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "579be97c-0dde-436e-805c-9bcb083b890e",
   "metadata": {},
   "source": [
    "dictLabels = {\n",
    "0:\"0\",\n",
    "1:\"1\",\n",
    "2:\"2\",\n",
    "3:\"3\",\n",
    "4:\"4\"\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7455b3de-f0cc-4ca2-980f-dc6a62f1171b",
   "metadata": {},
   "source": [
    "afficheDataset(donnees[\"train_images\"],donnees[\"train_labels\"],taille=10,image=64,dictLabels=dictLabels)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9fd3a0e8-5918-4ad1-a36e-94a800873fde",
   "metadata": {},
   "source": [
    "## <b><div style='padding:15px;background-color:#d8dcd6;color:#030aa7;font-size:100%; border-radius:10px 10px; box-shadow: 8px 8px 8px #042b4c;text-align: left'>BreastMNIST - Grey</div></b>\n",
    "\n",
    "The **BreastMNIST** is based on a dataset of 780 breast ultrasound images.<br> \n",
    "It is categorized into 3 classes: normal, benign, and malignant.<br>\n",
    "As we use low-resolution images, we simplify the task into binary classification by combining normal and benign as positive and classifying them against malignant as negative. We split the source dataset with a ratio of 7:1:2 into training, validation and test set.<br>\n",
    "The source images of 1×500×500 are resized into 1×28×28.\n",
    "\n",
    ">> https://zenodo.org/records/10519652/files/breastmnist.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/breastmnist_64.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/breastmnist_128.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/breastmnist_224.npz"
   ]
  },
  {
   "cell_type": "code",
   "id": "c6f74b91-6b57-40c3-b532-6b0b7ac28cc9",
   "metadata": {},
   "source": [
    "donnees = np.load(\"../donnees/MedMNIST(Standardized Biomedical Image)/breastmnist.npz\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "936e1238-5fda-4a99-b2dc-f76045c4c13e",
   "metadata": {},
   "source": [
    "print(f'apprentissage\\t{donnees[\"train_images\"].shape[0]}\\nvalidation\\t{donnees[\"val_images\"].shape[0]}\\ntest\\t\\t{donnees[\"test_images\"].shape[0]}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a88e2e15-1ede-47cf-992b-ac41e4ed7a14",
   "metadata": {},
   "source": [
    "dictLabels = {\n",
    "0: \"malignant\",\n",
    "1: \"normal, benign\"\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "98a3275c-89d3-451f-b557-98fd339fbe6a",
   "metadata": {},
   "source": [
    "afficheDataset(donnees[\"train_images\"],donnees[\"train_labels\"],taille=20,image=64,dictLabels=dictLabels,cmap='gray')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6bf684ee-727b-4e1e-bc9d-c60dac806f89",
   "metadata": {},
   "source": [
    "## <b><div style='padding:15px;background-color:#d8dcd6;color:#030aa7;font-size:100%; border-radius:10px 10px; box-shadow: 8px 8px 8px #042b4c;text-align: left'>BloodMNIST - RGB</div></b>\n",
    "\n",
    "The **BloodMNIST** is based on a dataset of individual normal cells, captured from individuals without infection, hematologic or oncologic disease and free of any pharmacologic treatment at the moment of blood collection.<br>\n",
    "It contains a total of **17,092** images and is organized into 8 classes. We split the source dataset with a ratio of 7:1:2 into training, validation and test set.<br>\n",
    "The source images with resolution 3×360×363 pixels are center-cropped into 3×200×200, and then resized into 3×28×28.\n",
    "\n",
    ">> https://zenodo.org/records/10519652/files/bloodmnist.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/bloodmnist_64.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/bloodmnist_128.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/bloodmnist_224.npz\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "b4ac4b22-ab9e-416f-9766-622d1870876d",
   "metadata": {},
   "source": [
    "donnees = np.load(\"../donnees/MedMNIST(Standardized Biomedical Image)/bloodmnist_64.npz\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c9346d04-6a27-4116-8ab4-66d059d55f66",
   "metadata": {},
   "source": [
    "print(f'apprentissage\\t{donnees[\"train_images\"].shape[0]}\\nvalidation\\t{donnees[\"val_images\"].shape[0]}\\ntest\\t\\t{donnees[\"test_images\"].shape[0]}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2b204b62-f8e6-46b1-9eb5-20e287478f4d",
   "metadata": {},
   "source": [
    "dictLabels = {0:\"basophil\",\n",
    "            1:\"eosinophil\",\n",
    "            2:\"erythroblast\",\n",
    "            3:\"immature\",# granulocytes(myelocytes, metamyelocytes and promyelocytes)\",\n",
    "            4:\"lymphocyte\",\n",
    "            5:\"monocyte\",\n",
    "            6:\"neutrophil\",\n",
    "            7:\"platelet\"}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2311ba4e-0374-4325-bc32-a7ff6cc7f1be",
   "metadata": {},
   "source": [
    "afficheDataset(donnees[\"train_images\"],donnees[\"train_labels\"],taille=10,image=56,dictLabels=dictLabels)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6badc3e3-c014-44fe-86b2-285700401489",
   "metadata": {},
   "source": [
    "## <b><div style='padding:15px;background-color:#d8dcd6;color:#030aa7;font-size:100%; border-radius:10px 10px; box-shadow: 8px 8px 8px #042b4c;text-align: left'>TissueMNIST - Gray</div></b>\n",
    "\n",
    "We use the **BBBC051**, available from the Broad Bioimage Benchmark Collection.<br>\n",
    "The dataset contains **236,386** human kidney cortex cells, segmented from 3 reference tissue specimens and organized into 8 categories.<br>\n",
    "We split the source dataset with a ratio of 7:1:2 into training, validation and test set. <br>\n",
    "Each gray-scale image is 32×32×7 pixels, where 7 denotes 7 slices. We take maximum values across the slices and resize them into 28×28 gray-scale images.\n",
    "\n",
    ">> https://zenodo.org/records/10519652/files/tissuemnist.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/tissuemnist_64.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/tissuemnist_128.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/tissuemnist_224.npz\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "411dc1b7-a52c-47ff-a6a4-3ce90c77d3ab",
   "metadata": {},
   "source": [
    "donnees = np.load(\"../donnees/MedMNIST(Standardized Biomedical Image)/tissuemnist_64.npz\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f932e128-5e4d-4c34-b085-fa8af244a4a6",
   "metadata": {},
   "source": [
    "print(f'apprentissage\\t{donnees[\"train_images\"].shape[0]}\\nvalidation\\t{donnees[\"val_images\"].shape[0]}\\ntest\\t\\t{donnees[\"test_images\"].shape[0]}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9dfb026a-46b2-42f3-98bd-a3e8e0ea3514",
   "metadata": {},
   "source": [
    "dictLabels = {\n",
    "0:\"Collecting Duct\\nConnecting Tubule\",\n",
    "1:\"Distal Convoluted Tubule\",\n",
    "2:\"Glomerular\\nendothelial cells\",\n",
    "3:\"Interstitial\\nendothelial cells\",\n",
    "4:\"Leukocytes\",\n",
    "5:\"Podocytes\",\n",
    "6:\"Proximal\\nTubule Segments\",\n",
    "7:\"Thick\\nAscending Limb\"\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6dda4e07-2d5d-4562-8099-6e808fbd23bf",
   "metadata": {},
   "source": [
    "afficheDataset(donnees[\"train_images\"],donnees[\"train_labels\"],taille=10,image=64,dictLabels=dictLabels,cmap='gray')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b432a3f6-ec8d-41e9-a758-2ecb6a7273b5",
   "metadata": {},
   "source": [
    "## <b><div style='padding:15px;background-color:#d8dcd6;color:#030aa7;font-size:100%; border-radius:10px 10px; box-shadow: 8px 8px 8px #042b4c;text-align: left'>OrganAMNIST - Gray</div></b>\n",
    "\n",
    "The **OrganAMNIST** is based on **3D computed tomography (CT)** images from **Liver Tumor Segmentation Benchmark (LiTS)**.<br>\n",
    "It is renamed from OrganMNIST_Axial (in MedMNIST v1) for simplicity.<br>\n",
    "We use bounding-box annotations of 11 body organs from another study to obtain the organ labels.<br>\n",
    "Hounsfield-Unit (HU) of the 3D images are transformed into gray-scale with an abdominal window.<br>\n",
    "We crop 2D images from the center slices of the 3D bounding boxes in axial views (planes).<br>\n",
    "The images are resized into 1×28×28 to perform multi-class classification of 11 body organs. 115 and 16 CT scans from the source training set are used as training and validation set, respectively.<br>\n",
    "The 70 CT scans from the source test set are treated as the test set.\n",
    "\n",
    ">> https://zenodo.org/records/10519652/files/organamnist.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/organamnist_64.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/organamnist_128.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/organamnist_224.npz\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "d322a052-f451-4203-b013-1fbb7257bb39",
   "metadata": {},
   "source": [
    "donnees = np.load(\"../donnees/MedMNIST(Standardized Biomedical Image)/organamnist_224.npz\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ac8c285d-4a71-4d85-9f4c-ce56bfddff7b",
   "metadata": {},
   "source": [
    "print(f'apprentissage\\t{donnees[\"train_images\"].shape[0]}\\nvalidation\\t{donnees[\"val_images\"].shape[0]}\\ntest\\t\\t{donnees[\"test_images\"].shape[0]}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "29d725a8-827d-4d56-96e1-431de05e968a",
   "metadata": {},
   "source": [
    "dictLabels = {\n",
    "0 : \"bladder\",\n",
    "1 : \"femur-left\",\n",
    "2 : \"femur-right\",\n",
    "3 : \"heart\",\n",
    "4 : \"kidney-left\",\n",
    "5 : \"kidney-right\",\n",
    "6 : \"liver\",\n",
    "7 : \"lung-left\",\n",
    "8 : \"lung-right\",\n",
    "9 : \"pancreas\",\n",
    "10 : \"spleen\"\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "118dc44a-bbc2-4277-9fe7-21eb105cc698",
   "metadata": {},
   "source": [
    "afficheDataset(donnees[\"train_images\"],donnees[\"train_labels\"],taille=10,image=64,dictLabels=dictLabels,cmap='gray')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a3c43401-7381-4cb0-a46e-95802b78a4f5",
   "metadata": {},
   "source": [
    "## <b><div style='padding:15px;background-color:#d8dcd6;color:#030aa7;font-size:100%; border-radius:10px 10px; box-shadow: 8px 8px 8px #042b4c;text-align: left'>OrganCMNIST - Gray</div></b>\n",
    "\n",
    "The **OrganAMNIST** is based on **3D computed tomography (CT)** images from **Liver Tumor Segmentation Benchmark (LiTS)**.<br>\n",
    "It is renamed from OrganMNIST_Axial (in MedMNIST v1) for simplicity.<br>\n",
    "We use bounding-box annotations of 11 body organs from another study to obtain the organ labels.<br>\n",
    "Hounsfield-Unit (HU) of the 3D images are transformed into gray-scale with an abdominal window.<br>\n",
    "We crop 2D images from the center slices of the 3D bounding boxes in axial views (planes).<br>\n",
    "The images are resized into 1×28×28 to perform multi-class classification of 11 body organs. 115 and 16 CT scans from the source training set are used as training and validation set, respectively.<br>\n",
    "The 70 CT scans from the source test set are treated as the test set.\n",
    "\n",
    ">> https://zenodo.org/records/10519652/files/organcmnist.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/organcmnist_64.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/organcmnist_128.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/organcmnist_224.npz\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "343426d6-bf87-49ca-906d-58a5d36a917a",
   "metadata": {},
   "source": [
    "donnees = np.load(\"../donnees/MedMNIST(Standardized Biomedical Image)/organcmnist_64.npz\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a4daf42f-40f3-4a28-9b2a-66c6d83dc42b",
   "metadata": {},
   "source": [
    "print(f'apprentissage\\t{donnees[\"train_images\"].shape[0]}\\nvalidation\\t{donnees[\"val_images\"].shape[0]}\\ntest\\t\\t{donnees[\"test_images\"].shape[0]}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bfa58529-64f2-413b-89d4-72fc281263d2",
   "metadata": {},
   "source": [
    "dictLabels = {\n",
    "0 : \"bladder\",\n",
    "1 : \"femur-left\",\n",
    "2 : \"femur-right\",\n",
    "3 : \"heart\",\n",
    "4 : \"kidney-left\",\n",
    "5 : \"kidney-right\",\n",
    "6 : \"liver\",\n",
    "7 : \"lung-left\",\n",
    "8 : \"lung-right\",\n",
    "9 : \"pancreas\",\n",
    "10 : \"spleen\"\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5d83e137-9e32-4687-a8ef-82cc8ccea1cf",
   "metadata": {},
   "source": [
    "afficheDataset(donnees[\"train_images\"],donnees[\"train_labels\"],taille=10,image=64,dictLabels=dictLabels,cmap='gray')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "53dfd5a9-7fda-42d9-b4eb-f4d7dfe48bf9",
   "metadata": {},
   "source": [
    "## <b><div style='padding:15px;background-color:#d8dcd6;color:#030aa7;font-size:100%; border-radius:10px 10px; box-shadow: 8px 8px 8px #042b4c;text-align: left'>OrganSMNIST - Gray</div></b>\n",
    "\n",
    "The **OrganAMNIST** is based on **3D computed tomography (CT)** images from **Liver Tumor Segmentation Benchmark (LiTS)**.<br>\n",
    "It is renamed from OrganMNIST_Axial (in MedMNIST v1) for simplicity.<br>\n",
    "We use bounding-box annotations of 11 body organs from another study to obtain the organ labels.<br>\n",
    "Hounsfield-Unit (HU) of the 3D images are transformed into gray-scale with an abdominal window.<br>\n",
    "We crop 2D images from the center slices of the 3D bounding boxes in axial views (planes).<br>\n",
    "The images are resized into 1×28×28 to perform multi-class classification of 11 body organs. 115 and 16 CT scans from the source training set are used as training and validation set, respectively.<br>\n",
    "The 70 CT scans from the source test set are treated as the test set.\n",
    "\n",
    ">> https://zenodo.org/records/10519652/files/organsmnist.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/organsmnist_64.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/organsmnist_128.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/organsmnist_224.npz\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "f9b9efad-ae86-4257-ae17-a49b509e0afa",
   "metadata": {},
   "source": [
    "donnees = np.load(\"../donnees/MedMNIST(Standardized Biomedical Image)/organsmnist_64.npz\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "98d0cb6d-6378-4dc6-91b4-919986a33f3c",
   "metadata": {},
   "source": [
    "print(f'apprentissage\\t{donnees[\"train_images\"].shape[0]}\\nvalidation\\t{donnees[\"val_images\"].shape[0]}\\ntest\\t\\t{donnees[\"test_images\"].shape[0]}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "94681c82-c8f3-4657-b8bf-3b12e1719457",
   "metadata": {},
   "source": [
    "dictLabels = {\n",
    "0 : \"bladder\",\n",
    "1 : \"femur-left\",\n",
    "2 : \"femur-right\",\n",
    "3 : \"heart\",\n",
    "4 : \"kidney-left\",\n",
    "5 : \"kidney-right\",\n",
    "6 : \"liver\",\n",
    "7 : \"lung-left\",\n",
    "8 : \"lung-right\",\n",
    "9 : \"pancreas\",\n",
    "10 : \"spleen\"\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "99207bde-b1e5-4512-b321-6ef268a5e72c",
   "metadata": {},
   "source": [
    "afficheDataset(donnees[\"train_images\"],donnees[\"train_labels\"],taille=10,image=64,dictLabels=dictLabels,cmap='gray')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d724de4c-a650-4c68-bdf5-08dce49fab30",
   "metadata": {},
   "source": [
    "## <b><div style='padding:15px;background-color:#d8dcd6;color:#030aa7;font-size:100%; border-radius:10px 10px; box-shadow: 8px 8px 8px #042b4c;text-align: left'>OrganMNIST3D - Gray</div></b>\n",
    "\n",
    "The source of the **OrganMNIST3D** is the same as that of the **Organ{A,C,S}MNIST**.<br>\n",
    "Instead of 2D images, we directly use the 3D bounding boxes and process the images into **28×28×28** to perform multi-class classification of 11 body organs.<br>\n",
    "The same 115 and 16 CT scans as the **Organ{A,C,S}MNIST** from the source training set are used as training and validation set, respectively, and the same 70 CT scans as the **Organ{A,C,S}MNIST** from the source test set are treated as the test set.\n",
    "\n",
    ">> https://zenodo.org/records/10519652/files/organmnist3d.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/organmnist3d_64.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/organmnist3d_128.npz<br>\n",
    ">> https://zenodo.org/records/10519652/files/organmnist3d_224.npz\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "2244b946-71d5-472b-9811-9c8f06ab3617",
   "metadata": {},
   "source": [
    "donnees = np.load(\"../donnees/MedMNIST(Standardized Biomedical Image)/organmnist3d.npz\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e44025ef-f0ea-47e9-ab6f-ed3e631c4773",
   "metadata": {},
   "source": [
    "print(f'image size:\\t{donnees[\"train_images\"].shape}\\napprentissage\\t{donnees[\"train_images\"].shape[0]}\\nvalidation\\t{donnees[\"val_images\"].shape[0]}\\ntest\\t\\t{donnees[\"test_images\"].shape[0]}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b852171a-57e5-47a1-9633-26dc53be7519",
   "metadata": {},
   "source": [
    "dictLabels = {\n",
    "0 : \"bladder\",\n",
    "1 : \"femur-left\",\n",
    "2 : \"femur-right\",\n",
    "3 : \"heart\",\n",
    "4 : \"kidney-left\",\n",
    "5 : \"kidney-right\",\n",
    "6 : \"liver\",\n",
    "7 : \"lung-left\",\n",
    "8 : \"lung-right\",\n",
    "9 : \"pancreas\",\n",
    "10 : \"spleen\"\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "80f6a6f0-1a58-4679-bc7e-6c5d9029d8b9",
   "metadata": {},
   "source": [
    "afficheDataset(donnees[\"train_images\"],donnees[\"train_labels\"],taille=10,image=64,dictLabels=dictLabels,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79315fbd-db61-432d-8dae-9bda73b94bf8",
   "metadata": {},
   "source": [
    "# <b><div style='padding:18px;background-color:#d8dcd6;color:#030aa7;font-size:130%; border-radius:12px 12px; box-shadow: 8px 8px 8px #042b4c;text-align: left'>Liste des échantillons de données</div></b>"
   ]
  },
  {
   "cell_type": "code",
   "id": "b4c4428c-f86b-4c8c-a5d1-0e54a647bb9d",
   "metadata": {},
   "source": [
    "listeEchantillons = {\n",
    "    'pathmnist':{\n",
    "                  0:\"adipose\",\n",
    "                  1:\"background\",\n",
    "                  2:\"debris\",\n",
    "                  3:\"lymphocytes\",\n",
    "                  4:\"mucus\",\n",
    "                  5:\"smooth\\nmuscle\",\n",
    "                  6:\"normal\\ncolon mucosa\",\n",
    "                  7:\"cancer-associated\\nstroma\",\n",
    "                  8:\"colorectal\\nadenocarcinoma\\nepithelium\"\n",
    "                 },\n",
    "    'chestmnist':{\n",
    "                  0: \"atelectasis\",\n",
    "                  1: \"cardiomegaly\",\n",
    "                  2: \"effusion\",\n",
    "                  3: \"infiltration\",\n",
    "                  4: \"mass\",\n",
    "                  5: \"nodule\",\n",
    "                  6: \"pneumonia\",\n",
    "                  7: \"pneumothorax\",\n",
    "                  8: \"consolidation\",\n",
    "                  9: \"edema\",\n",
    "                  10: \"emphysema\",\n",
    "                  11: \"fibrosis\",\n",
    "                  12: \"pleural\",\n",
    "                  13: \"hernia\"\n",
    "                 },\n",
    "    'dermamnist':{\n",
    "                  0:\"actinic keratoses\\nand intraepithelial carcinoma\",\n",
    "                  1:\"basal cell carcinoma\",\n",
    "                  2:\"benign keratosis-like lesions\",\n",
    "                  3:\"dermatofibroma\",\n",
    "                  4:\"melanoma\",\n",
    "                  5:\"melanocytic nevi\",\n",
    "                  6:\"vascular lesions\"\n",
    "                  },\n",
    "    'octmnist':{\n",
    "                  0: \"choroidal\\nneovascularization\",\n",
    "                  1: \"diabetic\\nmacular\\nedema\",\n",
    "                  2: \"drusen\",\n",
    "                  3: \"normal\"\n",
    "                  },\n",
    "    'pneumoniamnist':{\n",
    "                  0: \"normal\",\n",
    "                  1: \"pneumonia\"\n",
    "                  },\n",
    "    'retinamnist':{\n",
    "                  0:\"0\",\n",
    "                  1:\"1\",\n",
    "                  2:\"2\",\n",
    "                  3:\"3\",\n",
    "                  4:\"4\"\n",
    "                  },\n",
    "    'breastmnist':{\n",
    "                  0: \"malignant\",\n",
    "                  1: \"normal, benign\"\n",
    "                  },\n",
    "    'bloodmnist':{\n",
    "                  0:\"basophil\",\n",
    "                  1:\"eosinophil\",\n",
    "                  2:\"erythroblast\",\n",
    "                  3:\"immature\",# granulocytes(myelocytes, metamyelocytes and promyelocytes)\",\n",
    "                  4:\"lymphocyte\",\n",
    "                  5:\"monocyte\",\n",
    "                  6:\"neutrophil\",\n",
    "                  7:\"platelet\"\n",
    "                  },\n",
    "    'tissuemnist':{\n",
    "                  0:\"Collecting Duct\\nConnecting Tubule\",\n",
    "                  1:\"Distal Convoluted Tubule\",\n",
    "                  2:\"Glomerular\\nendothelial cells\",\n",
    "                  3:\"Interstitial\\nendothelial cells\",\n",
    "                  4:\"Leukocytes\",\n",
    "                  5:\"Podocytes\",\n",
    "                  6:\"Proximal\\nTubule Segments\",\n",
    "                  7:\"Thick\\nAscending Limb\"\n",
    "                  },\n",
    "    'organamnist':{\n",
    "                  0 : \"bladder\",\n",
    "                  1 : \"femur-left\",\n",
    "                  2 : \"femur-right\",\n",
    "                  3 : \"heart\",\n",
    "                  4 : \"kidney-left\",\n",
    "                  5 : \"kidney-right\",\n",
    "                  6 : \"liver\",\n",
    "                  7 : \"lung-left\",\n",
    "                  8 : \"lung-right\",\n",
    "                  9 : \"pancreas\",\n",
    "                  10 : \"spleen\"\n",
    "                  }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "92602a58-77b0-4621-81ca-9c83fd2c3f7c",
   "metadata": {},
   "source": [
    "# <b><div style='padding:18px;background-color:#d8dcd6;color:#030aa7;font-size:130%; border-radius:12px 12px; box-shadow: 8px 8px 8px #042b4c;text-align: left'>Création des fichiers TFRecors</div></b>"
   ]
  },
  {
   "cell_type": "code",
   "id": "b892f0df-95f8-431f-af78-468b772ed529",
   "metadata": {},
   "source": [
    "def creationTFRecords(nom,echantillon,donnees,repertoireSauvegardes):\n",
    "    def _bytes_feature(value):\n",
    "        if isinstance(value, type(tf.constant(0))): value = value.numpy()  \n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "    \n",
    "    def _float_feature(value):\n",
    "        return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "    \n",
    "    def _int64_feature(value):\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "    \n",
    "    def _formatageEnregistrement(image, label):\n",
    "        if len(image.shape) == 2 : image = np.expand_dims(image, axis=-1)\n",
    "        image = tf.image.encode_jpeg(image)\n",
    "        formatTFRecord = {\n",
    "                          'image': _bytes_feature(image),\n",
    "                          'label': _int64_feature(label)\n",
    "                          }\n",
    "        return tf.train.Example(features=tf.train.Features(feature=formatTFRecord)).SerializeToString()\n",
    "    \n",
    "    nomEchantillon = {\"apprentissage\":\"train\",\n",
    "                      \"validation\":\"val\",\n",
    "                      \"test\":\"test\"}\n",
    "        \n",
    "    fichierSharde = tf.io.TFRecordWriter(os.path.join(repertoireSauvegardes,f'{nom}-{echantillon}.tfrecords'))\n",
    "    for i, (image, label) in enumerate(zip(donnees[f'{nomEchantillon[echantillon]}_images'], \n",
    "                                           donnees[f'{nomEchantillon[echantillon]}_labels'])):  \n",
    "        fichierSharde.write(_formatageEnregistrement(image.astype(\"uint8\"), label[0]))\n",
    "\n",
    "    fichierSharde.close() "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9984c3eb-ee6b-47e3-9e62-d2f55f244b37",
   "metadata": {},
   "source": [
    "for nom in listeEchantillons:\n",
    "    print(nom)\n",
    "    donnees = np.load(f\"../donnees/MedMNIST(Standardized Biomedical Image)/{nom}.npz\")\n",
    "    creationTFRecords(nom,'apprentissage',donnees,repertoireSauvegardes)\n",
    "    creationTFRecords(nom,'validation',donnees,repertoireSauvegardes)\n",
    "    creationTFRecords(nom,'test',donnees,repertoireSauvegardes)    \n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "baea13ec-8e5e-4f04-a20f-118eadffaea9",
   "metadata": {},
   "source": [
    "repertoireSauvegardes"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fa3bc94e-303a-4214-8c62-7bb47f977d6d",
   "metadata": {},
   "source": [
    "for nom in ['pathmnist_224',\n",
    "            'octmnist_224',\n",
    "            'bloodmnist_224',\n",
    "            'tissuemnist_224',\n",
    "            'organamnist_224']:\n",
    "    print(nom)\n",
    "    donnees = np.load(f\"../donnees/MedMNIST(Standardized Biomedical Image)/{nom}.npz\")\n",
    "    creationTFRecords(nom,'apprentissage',donnees,repertoireSauvegardes)\n",
    "    creationTFRecords(nom,'validation',donnees,repertoireSauvegardes)\n",
    "    creationTFRecords(nom,'test',donnees,repertoireSauvegardes)    \n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6985af1c-efe2-4339-af41-d8302dbdc0ee",
   "metadata": {},
   "source": [
    "# <b><div style='padding:18px;background-color:#d8dcd6;color:#030aa7;font-size:130%; border-radius:12px 12px; box-shadow: 8px 8px 8px #042b4c;text-align: left'>Contrôle des fichiers TFRecors</div></b>"
   ]
  },
  {
   "cell_type": "code",
   "id": "5e4e8575-c7e6-40ec-af71-91592060057a",
   "metadata": {},
   "source": [
    "def controleFichiersTfRecords(nom,dictLabels):\n",
    "    def _traitementImage(image):\n",
    "        image = tf.cast(tf.image.decode_jpeg(image, channels=3), tf.int32)\n",
    "        return image\n",
    "    \n",
    "    def _lectureTFRecord(enregistrement):\n",
    "        formatTFRecord = ({\n",
    "            'image': tf.io.FixedLenFeature([], tf.string),\n",
    "            'label':  tf.io.FixedLenFeature([], tf.int64),\n",
    "        })\n",
    "    \n",
    "        enregistrement = tf.io.parse_single_example(enregistrement, formatTFRecord)\n",
    "        enregistrement['image'] =  _traitementImage(enregistrement['image'])\n",
    "        return enregistrement\n",
    "    \n",
    "    def _dictToImageLabel(enregistrement):\n",
    "        # return enregistrement['image'],tf.one_hot(enregistrement['label'], 5)\n",
    "        return enregistrement['image'],enregistrement['label']\n",
    "    \n",
    "    pipeline_train = tf.data.TFRecordDataset(os.path.join(repertoireSauvegardes,f'{nom}-apprentissage.tfrecords'))\n",
    "    pipeline_train = pipeline_train.map(_lectureTFRecord)\n",
    "    pipeline_train = pipeline_train.map(_dictToImageLabel)\n",
    "    pipeline_train = pipeline_train.batch(25)\n",
    "    pipeline_train = pipeline_train.prefetch(tf.data.AUTOTUNE)  \n",
    "    \n",
    "    image_batch, label_batch = next(iter(pipeline_train))\n",
    "    \n",
    "    plt.figure(figsize=(24, 24))\n",
    "    for n in range(25):\n",
    "        ax = plt.subplot(5, 5, n + 1)\n",
    "        plt.imshow(image_batch[n])\n",
    "        plt.title(dictLabels[label_batch[n].numpy()])\n",
    "        plt.axis(\"off\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ff85c27a-42ae-4d12-9daf-5cfe28075ce9",
   "metadata": {},
   "source": [
    "for nom in listeEchantillons:\n",
    "    controleFichiersTfRecords(nom,listeEchantillons[nom])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "80203547-983f-484e-a4a2-0e521cc23963",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b14928a2-0bb1-4ad2-adf9-596b529cd894",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d81e947d-9d9b-430f-ace5-ba26272b9e17",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "86eac435-4c38-42e4-bee1-9fb477ce9f4a",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f682a923-7073-4f63-9f31-30eb8dc6ea03",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d85efde6-3e1b-4f25-b5e1-dffedd3ee4fa",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b8219fee-6d77-4680-82b3-999675d09292",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9c379263-f21c-43f3-bfb2-d9c13a9821aa",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d3c4a53c-2282-4fad-ac10-fe7b18236124",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "164e39c9-33b6-43ff-bd2e-1540997ab675",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
