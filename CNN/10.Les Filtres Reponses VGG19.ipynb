{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> https://www.larousse.fr/dictionnaires/francais/inf%C3%A9rence/42907<br><br>\n",
    "\n",
    ">> **inférence** : Opération par laquelle on passe d'une assertion considérée comme vraie à une autre assertion au moyen d'un système de règles qui rend cette deuxième assertion également vraie.<br>\n",
    "\n",
    ">> **Inférence statistique** : Ensemble des méthodes permettant de formuler en termes probabilistes un jugement sur une population à partir des résultats observés sur un échantillon extrait au hasard de cette population.<br>\n",
    " \n",
    "\n",
    "# <b><div style='padding:18px;background-color:#d8dcd6;color:#030aa7;font-size:130%; border-radius:12px 12px; box-shadow: 8px 8px 8px #042b4c;text-align: left'>Initialisation du document</div></b>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "# import json\n",
    "# @param [\"tensorflow\", \"jax\", \"torch\"]\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'  \n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "# os.environ['TF_XLA_FLAGS']='--tf_xla_auto_jit=1,--tf_xla_always_defer_compilation=true'\n",
    "# os.environ['XLA_FLAGS']='--xla_backend_optimization_level=0,--xla_gpu_autotune_level=4,--xla_gpu_disable_ptxas_optimizations=true,--xla_gpu_use_cudnn_batchnorm_level=2'\n",
    "# os.environ['TF_GPU_ALLOCATOR']='cuda_malloc_async'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='5'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b><div style='padding:15px;background-color:#d8dcd6;color:#030aa7;font-size:100%; border-radius:10px 10px; box-shadow: 8px 8px 8px #042b4c;text-align: left'>Import libriries </div></b>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np, pandas as pd, seaborn as sns, warnings, os, sys, pickle, time\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "if int(str(sns.__version__).split('.')[1]) > 8 : \n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "else:\n",
    "    plt.style.use('seaborn-darkgrid')\n",
    "    \n",
    "sns.set(font_scale=2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist,fashion_mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import make_scorer, confusion_matrix, roc_curve, auc, accuracy_score, log_loss, hamming_loss, \\\n",
    "                            precision_score, recall_score, f1_score, fbeta_score, jaccard_score, \\\n",
    "                            precision_recall_curve, average_precision_score, balanced_accuracy_score, \\\n",
    "                            classification_report,roc_auc_score\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')# Suppress TensorFlow logging (2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"Tensorflow\\t : %s\\tCUDA %s\\tGPU %s\\tXLA %s\\nKeras\\t\\t : %s\\nPandas\\t\\t : %s\\nNumPy\\t\\t : %s\"%\n",
    "      (tf.__version__, \n",
    "       tf.test.is_built_with_cuda(), \n",
    "       tf.test.is_built_with_gpu_support(), \n",
    "       tf.test.is_built_with_xla(), \n",
    "       tf.keras.__version__, \n",
    "       pd.__version__, \n",
    "       np.__version__))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T07:44:46.253331Z",
     "start_time": "2021-09-04T07:44:45.377287Z"
    }
   },
   "source": [
    "# <b><div style='padding:18px;background-color:#d8dcd6;color:#030aa7;font-size:130%; border-radius:12px 12px; box-shadow: 8px 8px 8px #042b4c;text-align: left'>Initialisation des GPUs presents</div></b>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if len(physical_devices) >  0 :\n",
    "    for i, gpu in enumerate(physical_devices):\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[i], True)\n",
    "\n",
    "    strategy = tf.distribute.experimental.CentralStorageStrategy()\n",
    "    print('Le système est initialisé avec {0:d} GPUs'.format(strategy.num_replicas_in_sync))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b><div style='padding:18px;background-color:#d8dcd6;color:#030aa7;font-size:130%; border-radius:12px 12px; box-shadow: 8px 8px 8px #042b4c;text-align: left'>Outils du document</div></b>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "palette = [\n",
    "            \"#030aa7\", \"#e50000\", \"#d8863b\", \"#005f6a\", \"#6b7c85\", \"#751973\", \"#d1e5f0\", \"#fddbc7\",\n",
    "            \"#ffffcb\", \"#12e193\", \"#d8dcd6\", \"#ffdaf0\", \"#dfc5fe\", \"#f5054f\", \"#a0450e\",\n",
    "            \"#0339f8\", \"#f4320c\", \"#fec615\", \"#017a79\", \"#85a3b2\", \"#fe2f4a\", \"#a00498\", \"#b04e0f\",\n",
    "            \"#0165fc\", \"#ff724c\", \"#fddc5c\", \"#11875d\", \"#89a0b0\", \"#fe828c\", \"#cb00f5\", \"#b75203\",\n",
    "            \"#0485d1\", \"#ff7855\", \"#fbeeac\", \"#0cb577\", \"#95a3a6\", \"#ffb7ce\", \"#c071fe\", \"#ca6b02\",\n",
    "            \"#92c5de\", \"#f4a582\", \"#fef69e\", \"#18d17b\", \"#c5c9c7\", \"#ffcfdc\", \"#caa0ff\", \"#cb7723\",\n",
    "            \"#d1e5f0\", \"#fddbc7\", \"#ffffcb\", \"#12e193\", \"#d8dcd6\", \"#ffdaf0\", \"#dfc5fe\", \"#d8863b\",\n",
    "            \"#030764\", \"#be0119\", \"#dbb40c\", \"#005249\", \"#3c4142\", \"#cb0162\", \"#5d1451\", \"#653700\",\n",
    "            \"#040348\", \"#67001f\", \"#b27a01\", \"#002d04\", \"#000000\", \"#a0025c\", \"#490648\", \"#3c0008\"\n",
    "          ]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "nom_projet                = \"10.Les Filtres Reponses VGG19\"\n",
    "repertoireProjet          = os.getcwd()\n",
    "repertoireEnregistrement  = repertoireProjet +'/'+nom_projet+ '/repertoire.images'\n",
    "repertoireSauvegardes     = repertoireProjet +'/'+nom_projet+ '/repertoire.sauvegardes'\n",
    "\n",
    "def controleExistenceRepertoire(directory, create_if_needed=True):\n",
    "    \"\"\"Voir si le répertoire existe. S'il n'existe pas il est créé.\"\"\"\n",
    "    path_exists = os.path.exists(directory)\n",
    "    if path_exists:\n",
    "        if not os.path.isdir(directory):\n",
    "            raise Exception(\"Trouvé le nom \"+directory+\" mais c'est un fichier, pas un répertoire\")\n",
    "            return False\n",
    "        return True\n",
    "    if create_if_needed:\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "controleExistenceRepertoire(repertoireEnregistrement)\n",
    "controleExistenceRepertoire(repertoireSauvegardes)\n",
    "\n",
    "def sauvegarderImage( fichier):\n",
    "    \"\"\"Enregistrez la figure. Appelez la méthode juste avant plt.show ().\"\"\"\n",
    "    plt.savefig(os.path.join(repertoireEnregistrement,\n",
    "                             fichier+f\"--{dt.now().strftime('%Y_%m_%d_%H.%M.%S')}.png\"), \n",
    "                             dpi=600, \n",
    "                             bbox_inches='tight')\n",
    "    \n",
    "def sauvegarderModelPoids(model, fichierPoids, repertoireSauvegardes=repertoireSauvegardes):\n",
    "    \"\"\"Enregistrez les poids du modèle Keras.\"\"\"\n",
    "    if fichierPoids != None:\n",
    "        controleExistenceRepertoire(repertoireSauvegardes)\n",
    "        nomFichier = os.path.join(repertoireSauvegardes, '{}.keras'.format(fichierPoids))\n",
    "        model.save_weights(nomFichier)\n",
    "\n",
    "def sauvegarderModel(model, fichier, repertoireSauvegardes=repertoireSauvegardes):\n",
    "    \"\"\"Enregistrez le modèle Keras.\"\"\"\n",
    "    if fichier != None:\n",
    "        controleExistenceRepertoire(repertoireSauvegardes)\n",
    "        nomFichier = os.path.join(repertoireSauvegardes, '{}.keras'.format(fichier))\n",
    "        model.save(nomFichier)\n",
    "\n",
    "def lectureModelPoids(model, fichier, repertoireSauvegardes=repertoireSauvegardes):\n",
    "    \"\"\"Si le fichier existe, il est chargé et retourne True, sinon retourne False.\"\"\"\n",
    "    nomFichier = os.path.join(repertoireSauvegardes, '{}.keras'.format(fichier))\n",
    "    if os.path.exists(nomFichier):\n",
    "        if os.path.isfile(nomFichier):\n",
    "            model.load_weights(nomFichier)\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def sauvegardeHistorique(model,\n",
    "                         repertoireSauvegardes,\n",
    "                         nomSauvegarde='one_hidden_layer_history_batch_size_1'):\n",
    "\n",
    "    history = pd.DataFrame( model.history)\n",
    "    history.reset_index(inplace=True)\n",
    "    history.rename(columns={'index':'epoch'},inplace=True)\n",
    "    history.to_parquet(os.path.join(repertoireSauvegardes,f'{nomSauvegarde}.gzip'),compression='gzip', engine='pyarrow') \n",
    "    return history\n",
    "\n",
    "def afficheHistoriqueEntrainement(history, palette, nom='afficheHistoriqueEntrainement'):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2,figsize=(48,16));\n",
    "    markersize = 8\n",
    "    linewidth=2\n",
    "    \n",
    "    graph = sns.lineplot(x='epoch', \n",
    "                         y='accuracy',  \n",
    "                         data=history,\n",
    "                         ax=ax[0],      \n",
    "                         label='accuracy',\n",
    "                         err_style=None, \n",
    "                         marker='o',\n",
    "                         markersize=markersize,\n",
    "                         linewidth=linewidth,\n",
    "                         color=palette[0],\n",
    "                         );\n",
    "    graph = sns.lineplot(x='epoch', \n",
    "                         y='val_accuracy',  \n",
    "                         data=history,\n",
    "                         ax=ax[0],      \n",
    "                         label='val_accuracy',\n",
    "                         err_style=None, \n",
    "                         marker='o',\n",
    "                         markersize=markersize,\n",
    "                         linewidth=linewidth,\n",
    "                         color=palette[1],\n",
    "                         );\n",
    "    \n",
    "    graph = sns.lineplot(x='epoch', \n",
    "                         y='loss',  \n",
    "                         data=history,\n",
    "                         ax=ax[1],      \n",
    "                         label='loss',\n",
    "                         err_style=None, \n",
    "                         marker='o',\n",
    "                         markersize=markersize,\n",
    "                         linewidth=linewidth,\n",
    "                         color=palette[0],\n",
    "                         );\n",
    "    graph = sns.lineplot(x='epoch', \n",
    "                         y='val_loss',  \n",
    "                         data=history,\n",
    "                         ax=ax[1],      \n",
    "                         label='val_loss',\n",
    "                         err_style=None, \n",
    "                         marker='o',\n",
    "                         markersize=markersize,\n",
    "                         linewidth=linewidth,\n",
    "                         color=palette[1],\n",
    "                         );\n",
    "    sauvegarderImage(nom)\n",
    "\n",
    "def afficheMatriceConfusion(observations,predictions,dictLabels):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    sns.set(font_scale=1.5)\n",
    "    sns.heatmap(pd.crosstab(observations,predictions), \n",
    "                fmt= '.0f',\n",
    "                linewidths=0.3,\n",
    "                #vmax=1.0, \n",
    "                square=True, \n",
    "                cmap=plt.cm.Blues,\n",
    "                linecolor='white', \n",
    "                annot=True,\n",
    "                cbar=False,\n",
    "                xticklabels=dictLabels.values(), \n",
    "                yticklabels=dictLabels.values()\n",
    "               );\n",
    "    plt.xlabel('Observations', fontsize = 18);\n",
    "    plt.ylabel('Prédictions', fontsize = 18);\n",
    "    sauvegarderImage('afficheMatriceConfusion')\n",
    "\n",
    "def executeApprentissageChoixClassifieurs(model,\n",
    "                                          X_test,\n",
    "                                          y_test,\n",
    "                                          label_dict,\n",
    "                                          couleurs,\n",
    "                                          nom_essai = 'initial'\n",
    "                                         ):\n",
    "    \n",
    "    def afficheCourbes(vraisPositifs,fauxPositifs,aucROCt,precisions,sensibilites,avgPrecRec,nbClasses,lw,label_dict):\n",
    "        plt.figure(figsize=(24, 24));\n",
    "        for i, color in zip(range(nbClasses), palette):\n",
    "            plt.plot(fauxPositifs[i], vraisPositifs[i], color=color, lw=lw,\n",
    "                     label=' ' + label_dict[i] + ' (AUC = {1:0.8f})'\n",
    "                                                             ''.format(i, aucROCt[i]))\n",
    "    \n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "        plt.xlim([-0.05, 1.05])\n",
    "        plt.ylim([-0.05, 1.05])\n",
    "        plt.xlabel('Taux de faux Positifs-(1 - Spécificité) = VN / (FP + VN)',size=18)\n",
    "        plt.ylabel('Taux de vrais positifs-Sensibilité = VP / (VP + FN)',size=18)\n",
    "        plt.title('Courbe ROC (Receiver Operating Caracteristic) -- ',size=20)\n",
    "        plt.legend(loc=\"lower right\"); #, fontsize='large'\n",
    "        sauvegarderImage('Courbe ROC')\n",
    "        \n",
    "        plt.figure(figsize=(24,24));\n",
    "    \n",
    "        f_scores = np.linspace(0.2, 0.9, num=8)\n",
    "        for f_score in f_scores:\n",
    "            x = np.linspace(0.01, 1)\n",
    "            y = f_score * x / (2 * x - f_score)\n",
    "            l, = plt.plot(x[y >= 0], y[y >= 0], color='gray', alpha=0.2)\n",
    "            plt.annotate('f1={0:0.1f}'.format(f_score), xy=(0.9, y[45] + 0.02))\n",
    "    \n",
    "        for i, color in zip(range(nbClasses), palette):\n",
    "            plt.step(sensibilites[i], \n",
    "                         precisions[i], \n",
    "                         where='post', \n",
    "                         color=color, \n",
    "                         lw=lw, \n",
    "                         label=f\"{label_dict[i]}(APR = {avgPrecRec[label_dict[i]]:0.8f})\"\n",
    "                    )\n",
    "            plt.fill_between(sensibilites[i], precisions[i], step='post', alpha=0.05)            \n",
    "    \n",
    "            # plt.plot(fauxPositifs[i], vraisPositifs[i], color=color, lw=lw,\n",
    "            #          label=' ' + label_dict[i] + ' (AUC = {1:0.8f})'\n",
    "            #                                                  ''.format(i, aucROCt[i]))        \n",
    "    \n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "        plt.xlim([-0.05, 1.05])\n",
    "        plt.ylim([-0.05, 1.05])        \n",
    "        plt.xlabel('Sensibilité/Rappel(Recall) = VP / (VP + FN)',size=18)\n",
    "        plt.ylabel('Précision = VP / (VP + FP)',size=18)        \n",
    "        plt.title('Courbe Précision-Rappel',size=20)\n",
    "        plt.legend(loc=\"lower right\") # , fontsize = 'large'\n",
    "        sauvegarderImage('Courbe Précision-Rappel')\n",
    "    \n",
    "    cvF1, cvF1SD, cvAccuracy, cvAccSD, aucROC, avgPrecRec, accuracy, balanced_accuracy, logloss, hammingloss, precision, sensibilite, \\\n",
    "    f1, f2, f05, jaccard, vrais_negatifs, faux_positifs, faux_negatifs, vrais_positifs, total_positifs, aucROCtn = \\\n",
    "        dict(), dict(), dict(), dict(), dict(), dict(), dict(), dict(), dict(), dict(), dict(), dict(),\\\n",
    "        dict(), dict(), dict(), dict(), dict(), dict(), dict(), dict(), dict(), dict()\n",
    "    #\n",
    "    oneloss, precision_micro, precision_macro, precision_weighted, \\\n",
    "    sensibilite_macro, sensibilite_micro, sensibilite_weighted, \\\n",
    "    f1_micro, f1_macro, f1_weighted,f2_micro,f2_macro,f2_weighted,f05_micro,f05_macro,f05_weighted = \\\n",
    "        dict(), dict(), dict(), dict(), dict(), dict(), dict(), dict(), \\\n",
    "        dict(), dict(), dict(), dict(), dict(), dict(), dict(), dict()\n",
    "    \n",
    "    fauxPositifs, vraisPositifs, precisions, sensibilites, aucROCt, pr_auc, tauxROC, tauxPR = dict(), dict(), dict(), dict(), dict(), dict(), dict(), dict()        \n",
    "    \n",
    "    \n",
    "    lw = 1\n",
    "    # couleurs    = sns.hls_palette(len(classifieursDict.keys()), l=.4, s=.9)\n",
    "    nbClasses   = len(dictLabels.keys())\n",
    "    listClasses = list(dictLabels.keys())\n",
    "    \n",
    "    y_testA  = label_binarize(y_test, classes=listClasses)\n",
    "    plt.figure(figsize=(18,18))\n",
    "    \n",
    "    \n",
    "    t1 = time.time()  \n",
    "    classifier = model\n",
    "    \n",
    "    # y_score     = model.predict_proba(X_test)\n",
    "    # y_pred      = model.predict(X_test)\n",
    "    y_score     = model.predict(X_test)\n",
    "    y_pred      = np.argmax(y_score, axis=-1) \n",
    "    y_predA     = label_binarize(y_pred, classes=listClasses)\n",
    "    \n",
    "    accuracy['global']              = accuracy_score(y_test, y_pred)\n",
    "    balanced_accuracy['global']     = balanced_accuracy_score(y_test, y_pred)\n",
    "    precision['global']             = precision_score(y_test, y_pred, average='weighted')\n",
    "    sensibilite['global']           = recall_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    f1['global']                    = f1_score(y_test, y_pred, average='weighted')\n",
    "    f2['global']                    = fbeta_score(y_test, y_pred, beta=2, average='weighted')\n",
    "    f05['global']                   = fbeta_score(y_test, y_pred, beta=0.5, average='weighted')\n",
    "    \n",
    "    vrais_negatifs['global']        = 0\n",
    "    faux_positifs ['global']        = 0\n",
    "    faux_negatifs ['global']        = 0\n",
    "    vrais_positifs['global']        = 0\n",
    "    total_positifs['global']        = 0\n",
    "    \n",
    "    \n",
    "    aucROC['global'] = roc_auc_score(y_test, y_score, multi_class='ovr')\n",
    "    \n",
    "    for i in range(nbClasses):\n",
    "        fauxPositifs[i], vraisPositifs[i], tauxROC[i] = roc_curve(y_testA[:, i], y_score[:, i])\n",
    "        aucROCt[i]                                    = auc(fauxPositifs[i], vraisPositifs[i])\n",
    "        precisions[i], sensibilites[i], tauxPR[i]     = precision_recall_curve(y_testA[:, i], y_score[:, i])\n",
    "    \n",
    "        aucROC[label_dict[i]]                = aucROCt[i]\n",
    "        avgPrecRec[label_dict[i]]            = average_precision_score(y_testA[:, i], y_score[:, i])\n",
    "        accuracy[label_dict[i]]              = accuracy_score(y_testA[:, i], y_predA[:, i])\n",
    "        balanced_accuracy[label_dict[i]]     = balanced_accuracy_score(y_testA[:, i],y_predA[:, i])\n",
    "        logloss[label_dict[i]]               = log_loss(y_testA[:, i], y_predA[:, i])\n",
    "        hammingloss[label_dict[i]]           = hamming_loss(y_testA[:, i], y_predA[:, i])\n",
    "        precision[label_dict[i]]             = precision_score(y_testA[:, i], y_predA[:, i])\n",
    "        sensibilite[label_dict[i]]           = recall_score(y_testA[:, i], y_predA[:, i])\n",
    "        f1[label_dict[i]]                    = f1_score(y_testA[:, i], y_predA[:, i])\n",
    "        f2[label_dict[i]]                    = fbeta_score(y_testA[:, i], y_predA[:, i], beta=2)\n",
    "        f05[label_dict[i]]                   = fbeta_score(y_testA[:, i], y_predA[:, i], beta=0.5)\n",
    "      \n",
    "        jaccard[label_dict[i]]               = jaccard_score(y_testA[:, i], y_predA[:, i])\n",
    "        vrais_negatifs[label_dict[i]]        = confusion_matrix(y_testA[:, i], y_predA[:, i])[0, 0]\n",
    "        faux_positifs[label_dict[i]]         = confusion_matrix(y_testA[:, i], y_predA[:, i])[0, 1]\n",
    "        faux_negatifs[label_dict[i]]         = confusion_matrix(y_testA[:, i], y_predA[:, i])[1, 0]\n",
    "        vrais_positifs[label_dict[i]]        = confusion_matrix(y_testA[:, i], y_predA[:, i])[1, 1]\n",
    "        total_positifs[label_dict[i]]        = vrais_positifs[label_dict[i]] + faux_negatifs [label_dict[i]]\n",
    "        vrais_negatifs['global']              += vrais_negatifs[label_dict[i]]\n",
    "        faux_positifs ['global']              += faux_positifs [label_dict[i]]\n",
    "        faux_negatifs ['global']              += faux_negatifs [label_dict[i]]\n",
    "        vrais_positifs['global']              += vrais_positifs[label_dict[i]]\n",
    "    \n",
    "    \n",
    "    total_positifs['global'] = vrais_positifs['global'] + faux_negatifs ['global']\n",
    "    \n",
    "    \n",
    "    fauxPositifs[\"micro\"], vraisPositifs[\"micro\"], _ = roc_curve(y_testA.ravel(), y_score.ravel())\n",
    "    aucROCt[\"micro\"]                                 = auc(fauxPositifs[\"micro\"], vraisPositifs[\"micro\"])\n",
    "    \n",
    "    listFauxPositifs = np.unique(np.concatenate([fauxPositifs[i] for i in range(nbClasses)]))\n",
    "    moyenneVraisPositifs = np.zeros_like(listFauxPositifs)\n",
    "    for i in range(nbClasses):\n",
    "        moyenneVraisPositifs += np.interp(listFauxPositifs, fauxPositifs[i], vraisPositifs[i])\n",
    "    \n",
    "    moyenneVraisPositifs /= nbClasses\n",
    "    \n",
    "    fauxPositifs[\"macro\"], vraisPositifs[\"macro\"] = listFauxPositifs, moyenneVraisPositifs\n",
    "    aucROCt[\"macro\"] = auc(fauxPositifs[\"macro\"], vraisPositifs[\"macro\"])\n",
    "    # aucROC['global'] = aucROCt[\"macro\"]  # (aucROCt[\"micro\"],aucROCt[\"macro\"])\n",
    "    \n",
    "    avgPrecRec['global'] = average_precision_score(y_testA.ravel(), y_score.ravel(), average='weighted')\n",
    "    \n",
    "    afficheCourbes(vraisPositifs,fauxPositifs,aucROCt,precisions,sensibilites,avgPrecRec,nbClasses,lw,label_dict);\n",
    "    \n",
    "    print (\"Area under the ROC curve : %0.4f\" % aucROC['global'],end='\\t--\\t')\n",
    "    print('Exécution  :'+('%.2fs' % (time.time() - t1)).lstrip('0'))\n",
    "        \n",
    "    resultats = pd.DataFrame(pd.Series(aucROC), columns=[\"aucROC\"])\n",
    "    resultats[\"avgPrecRec\"]              = pd.Series(avgPrecRec)\n",
    "    resultats[\"f1\"]                      = pd.Series(f1)\n",
    "    resultats[\"f2\"]                      = pd.Series(f2)\n",
    "    resultats[\"f05\"]                     = pd.Series(f05)\n",
    "    resultats[\"accuracy\"]                = pd.Series(accuracy)\n",
    "    \n",
    "    resultats[\"precision\"]               = pd.Series(precision)\n",
    "    resultats[\"sensibilite\"]             = pd.Series(sensibilite)\n",
    "    resultats[\"vrais_positifs\"]          = pd.Series(vrais_positifs)\n",
    "    resultats[\"vrais_negatifs\"]          = pd.Series(vrais_negatifs)\n",
    "    resultats[\"faux_positifs\"]           = pd.Series(faux_positifs)\n",
    "    resultats[\"faux_negatifs\"]           = pd.Series(faux_negatifs)\n",
    "    resultats[\"total_positifs\"]          = pd.Series(total_positifs)\n",
    "    \n",
    "    resultats.reset_index(inplace=True)\n",
    "    resultats.rename(columns={\"index\": \"Classe\"}, inplace=True)\n",
    "    resultats['essai'] = nom_essai\n",
    "    return resultats\n",
    "\n",
    "def affichePrediction(model, img_path, decode_predictions, preprocess_input, size=(224, 224)):\n",
    "    \n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=size)\n",
    "    x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    preds = model.predict(x)\n",
    "\n",
    "    prediction = pd.DataFrame({'Classe':[x[1] for x in decode_predictions(preds)[0]],\n",
    "                               'Probabilite':[x[2] for x in decode_predictions(preds)[0]]})\n",
    "    fig = plt.figure(figsize=(36,18))\n",
    "    fig.subplots_adjust(wspace=0.3)\n",
    "    plt.subplot(1,2,1)\n",
    "    \n",
    "    img = plt.imread(img_path)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img);\n",
    "    plt.subplot(1,2,2)\n",
    "\n",
    "    graph = sns.barplot(\n",
    "                        x='Classe',\n",
    "                        y='Probabilite',\n",
    "                        data=prediction.sort_values('Probabilite',ascending=False),\n",
    "                        palette=palette[1:]\n",
    "                        );\n",
    "    for patche in graph.patches:\n",
    "        if patche.get_height() > 0 :\n",
    "            graph.text(\n",
    "                        patche.get_x()+0.4,\n",
    "                        2*patche.get_height()/3,\n",
    "                        f'{patche.get_height()*100:0.2f}%',\n",
    "                        color='black',\n",
    "                        rotation='vertical',\n",
    "                        # size='large',\n",
    "                        fontsize='large',\n",
    "                        bbox=dict(boxstyle='round', facecolor='white', alpha=0.6),\n",
    "                        verticalalignment='center',\n",
    "                        horizontalalignment='center',\n",
    "                       )       \n",
    "            \n",
    "    sauvegarderImage('affichePrediction')\n",
    "    return prediction\n",
    "\n",
    "# This image might have a very wide range of values, so center them\n",
    "# and scale by the standard deviation so that we see most of the values\n",
    "def prep_image_for_display(input_image):\n",
    "    image = np.copy(input_image)\n",
    "    image -= image.mean()\n",
    "    image /= (image.std() + 1e-5)\n",
    "    image *= 64\n",
    "    image += 128\n",
    "    image = np.clip(image, 0, 255).astype('uint8')\n",
    "    return image\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b><div style='padding:18px;background-color:#d8dcd6;color:#030aa7;font-size:130%; border-radius:12px 12px; box-shadow: 8px 8px 8px #042b4c;text-align: left'>Lecture des données</div></b>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!ls -al ../images/donnees/jason.jpg"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "jason = '../images/donnees/jason.jpg'\n",
    "img = tf.keras.preprocessing.image.load_img(jason, target_size=(224, 224))\n",
    "img_tensor = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "img_tensor /= 255\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(img_tensor[0])\n",
    "\n",
    "print(img_tensor.shape)\n",
    "\n",
    "img_tensor -= 0.5"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b><div style='padding:18px;background-color:#d8dcd6;color:#030aa7;font-size:130%; border-radius:12px 12px; box-shadow: 8px 8px 8px #042b4c;text-align: left'>Chargement du modèles VGG19</div></b>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "modelVGG19 = tf.keras.applications.VGG19(weights='imagenet')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "modelVGG19.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b><div style='padding:15px;background-color:#d8dcd6;color:#030aa7;font-size:100%; border-radius:10px 10px; box-shadow: 8px 8px 8px #042b4c;text-align: left'>Inférence</div></b>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "prediction = affichePrediction(modelVGG19, \n",
    "                  '../images/donnees/jason.jpg', \n",
    "                  decode_predictions=tf.keras.applications.vgg19.decode_predictions,\n",
    "                  preprocess_input=tf.keras.applications.vgg19.preprocess_input, \n",
    "                  size=(224, 224))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b><div style='padding:15px;background-color:#d8dcd6;color:#030aa7;font-size:100%; border-radius:10px 10px; box-shadow: 8px 8px 8px #042b4c;text-align: left'>Couches du modèle</div></b>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "modelVGG19.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "dictLayers = {i:layer.name for i,layer in enumerate(modelVGG19.layers[1:-4])}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b><div style='padding:15px;background-color:#d8dcd6;color:#030aa7;font-size:100%; border-radius:10px 10px; box-shadow: 8px 8px 8px #042b4c;text-align: left'>Modèle pour recouper les images transformées de chaque couche</div></b>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Get the output of every layer\n",
    "layer_outputs = [layer.output for layer in modelVGG19.layers[1:-4]]\n",
    "\n",
    "# Creates a model that will return these outputs, given the model input:\n",
    "activation_model = tf.keras.models.Model(inputs=modelVGG19.input, outputs=layer_outputs)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b><div style='padding:15px;background-color:#d8dcd6;color:#030aa7;font-size:100%; border-radius:10px 10px; box-shadow: 8px 8px 8px #042b4c;text-align: left'>Images transformées de chaque couche</div></b>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "img_activations = activation_model.predict(img_tensor)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b><div style='padding:15px;background-color:#d8dcd6;color:#030aa7;font-size:100%; border-radius:10px 10px; box-shadow: 8px 8px 8px #042b4c;text-align: left'>Affichage des images transformées de chaque couche</div></b>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for i in dictLayers:\n",
    "    if dictLayers[i][7:11] == 'conv' : \n",
    "        print(dictLayers[i])\n",
    "        plt.figure(figsize=(24,24))\n",
    "        for j in range(64):\n",
    "            image = np.copy(img_activations[i][0, :, :, j])\n",
    "            image = np.clip(image, 0, 255)\n",
    "            plt.subplot(8, 8, j+1)\n",
    "            plt.title(j+1, fontsize=14, y=1.03)\n",
    "            plt.imshow(image,cmap='grey')\n",
    "            plt.axis('off')\n",
    "            plt.tick_params(labelbottom='off', labelleft='off')  \n",
    "        sauvegarderImage(f'{dictLayers[i]}')\n",
    "        plt.show()\n",
    "        \n",
    "    "
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
